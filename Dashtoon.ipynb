{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaU2iIytydRF"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "!pip install Pillow\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.utils import save_image\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using vgg19 model\n",
        "model = models.vgg19(pretrained=True).features"
      ],
      "metadata": {
        "id": "8-XxvB5CzlQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a class to initialize number of features and model\n",
        "class VGG(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(VGG,self).__init__()\n",
        "    self.chosen_features = ['0', '5', '10', '19', '28']\n",
        "    self.model = models.vgg19(pretrained = True).features[:29]\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Creating feature matrix\n",
        "    features = []\n",
        "\n",
        "    for layer_num, layer in enumerate(self.model):\n",
        "      x = layer(x)\n",
        "      if str(layer_num) in self.chosen_features:\n",
        "        features.append(x)\n",
        "\n",
        "    return features\n",
        "\n",
        "# Function to load image\n",
        "def load_image(image_name):\n",
        "  image = Image.open(image_name)\n",
        "  image = loader(image).unsqueeze(0)\n",
        "  return image.to(device)\n",
        "\n",
        "# Selecting appropriate device to train the model on\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
        "image_size = 356\n",
        "\n",
        "# Prepocessing image i.e. resizing it and converting it to tensor object\n",
        "loader = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((image_size, image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize(mean=[], std=[])\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Loading image\n",
        "original_img = load_image(\"/content/annahathaway.png\")\n",
        "style_img = load_image(\"/content/style.jpg\")\n",
        "model = VGG().to(device).eval()\n",
        "\n",
        "generated = original_img.clone().requires_grad_(True)\n",
        "\n",
        "# Hyperparameters\n",
        "\n",
        "total_steps = 6000\n",
        "learning_rate = 0.001\n",
        "alpha = 1\n",
        "beta = 0.01\n",
        "\n",
        "optimizer = optim.Adam([generated], lr = learning_rate)\n",
        "\n",
        "# Training model\n",
        "for step in range(total_steps):\n",
        "  generated_features = model(generated)\n",
        "  original_img_features = model(original_img)\n",
        "  style_features = model(style_img)\n",
        "\n",
        "  style_loss = original_loss = 0\n",
        "\n",
        "  for gen_feature, orig_feature, style_feature in zip(\n",
        "      generated_features, original_img_features, style_features\n",
        "  ):\n",
        "    batch_size, channel, height, width = gen_feature.shape\n",
        "    original_loss += torch.mean((gen_feature - orig_feature) ** 2)\n",
        "\n",
        "    # Compute Gram Matrix\n",
        "    G = gen_feature.view(channel, height*width).mm(\n",
        "        gen_feature.view(channel, height*width).t()\n",
        "    )\n",
        "\n",
        "    A = style_feature.view(channel, height*width).mm(\n",
        "        style_feature.view(channel, height*width).t()\n",
        "    )\n",
        "\n",
        "    style_loss += torch.mean((G - A)**2)\n",
        "\n",
        "  # Calculating loss\n",
        "  total_loss = alpha*original_loss + beta * style_loss\n",
        "  optimizer.zero_grad()\n",
        "  total_loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if step % 200==0:\n",
        "    print(total_loss)\n",
        "    # Generated image to compare it with original image and evaluate it\n",
        "    save_image(generated, \"generated.png\")\n"
      ],
      "metadata": {
        "id": "UHi5OlA90PNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hVEhw1Hlppe2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}